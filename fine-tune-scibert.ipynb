{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224be40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6832748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version from Kaggle using dataset handle\n",
    "# path = kagglehub.dataset_download(\"spsayakpaul/arxiv-paper-abstracts\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79310082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"ivanmitriakhin/arxiv-titles-abstracts-and-tags\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2713943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers[torch]==4.38.0 datasets pandas scikit-learn tabulate accelerate==0.27.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bffeea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9716cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/User/Desktop/bert/12venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import re\n",
    "import transformers\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f899e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration ---\n",
    "file_path = 'arxiv_data_grouped.csv'\n",
    "title_column = 'titles'\n",
    "abstract_column = 'abstracts'\n",
    "MODEL_CHECKPOINT = 'allenai/scibert_scivocab_uncased'\n",
    "output_model_dir = './fine-tuned-scibert-multilabel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd294af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: arxiv_data_grouped.csv\n",
      "Cleaning text data...\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Data Loading and Cleaning ---\n",
    "print(f\"Loading data from: {file_path}\")\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str): \n",
    "        return \"\"\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "print(\"Cleaning text data...\")\n",
    "df[title_column] = df[title_column].apply(clean_text)\n",
    "df[abstract_column] = df[abstract_column].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d0f904d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (536914, 2)\n",
      "Number of label classes: 8\n",
      "Sample labels: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Data Preprocessing ---\n",
    "first_label_index = df.columns.get_loc(abstract_column) + 1\n",
    "label_columns = df.columns[first_label_index:].tolist()\n",
    "df['text'] = df[title_column] + \" [SEP] \" + df[abstract_column]\n",
    "\n",
    "# Convert labels to float32 numpy arrays (this ensures proper dtype)\n",
    "df['labels'] = df[label_columns].values.astype(np.float32).tolist()\n",
    "df_clean = df[['text', 'labels']]\n",
    "\n",
    "print(f\"Dataset shape: {df_clean.shape}\")\n",
    "print(f\"Number of label classes: {len(label_columns)}\")\n",
    "print(f\"Sample labels: {df_clean['labels'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "516b9e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/User/Desktop/bert/12venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Tokenization ---\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3fb7179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 536914/536914 [01:43<00:00, 5189.05 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting dataset format to PyTorch tensors...\n",
      "Labels type: <class 'torch.Tensor'>\n",
      "Labels dtype: torch.float32\n",
      "Sample labels: tensor([1., 0., 0., 0., 0., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Dataset Creation and Processing ---\n",
    "print(\"Creating dataset...\")\n",
    "full_dataset = Dataset.from_pandas(df_clean)\n",
    "\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = full_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Remove text column (no longer needed)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(['text'])\n",
    "\n",
    "# Set format to torch tensors (this handles the float32 conversion automatically)\n",
    "print(\"Setting dataset format to PyTorch tensors...\")\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Verify the conversion worked\n",
    "sample = tokenized_dataset[0]\n",
    "print(f\"Labels type: {type(sample['labels'])}\")\n",
    "print(f\"Labels dtype: {sample['labels'].dtype}\")\n",
    "print(f\"Sample labels: {sample['labels']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c4899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset...\n",
      "Train dataset size: 429531\n",
      "Eval dataset size: 107383\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Train/Test Split ---\n",
    "print(\"Splitting dataset...\")\n",
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Eval dataset size: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f02e912f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Model Loading ---\n",
    "print(\"Loading model...\")\n",
    "num_labels = len(label_columns)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8db6e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Metrics Function ---\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    # Convert to probabilities\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(logits))\n",
    "    \n",
    "    # Convert to predictions (threshold = 0.5)\n",
    "    predictions = np.zeros(probs.shape)\n",
    "    predictions[np.where(probs >= 0.5)] = 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1_micro = f1_score(labels, predictions, average='micro')\n",
    "    f1_macro = f1_score(labels, predictions, average='macro')\n",
    "    roc_auc = roc_auc_score(labels, predictions, average='micro')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'roc_auc': roc_auc,\n",
    "        'accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca101fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Training Arguments ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=128,    \n",
    "    per_device_eval_batch_size=128,\n",
    "    \n",
    "    # Add these optimizations:\n",
    "    fp16=True,                         # Half precision (faster + less memory)\n",
    "    dataloader_num_workers=2,          # Parallel data loading\n",
    "    dataloader_pin_memory=True,        # Faster transfer\n",
    "    gradient_checkpointing=True,       # Save memory\n",
    "    \n",
    "    # Existing settings...\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_micro\",\n",
    "    greater_is_better=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d874d6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICATION - Batch size: 128\n",
      "Expected steps per epoch: 3355\n"
     ]
    }
   ],
   "source": [
    "print(f\"VERIFICATION - Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Expected steps per epoch: {len(train_dataset) // training_args.per_device_train_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd13707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 429531\n",
      "Batch size: 128\n",
      "Gradient accumulation steps: 1\n",
      "Expected calculation: 429531 ÷ 128 = 3355\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Gradient accumulation steps: {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"Expected calculation: {len(train_dataset)} ÷ {training_args.per_device_train_batch_size} = {len(train_dataset) // training_args.per_device_train_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590b2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING MODEL TRAINING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/User/Desktop/bert/12venv/lib/python3.12/site-packages/accelerate/accelerator.py:450: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/mnt/c/Users/User/Desktop/bert/12venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='10068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   42/10068 02:10 < 9:06:57, 0.31 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 10. Trainer Initialization and Training ---\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Add early stopping callback\n",
    "\n",
    ")\n",
    "\n",
    "print(\"STARTING MODEL TRAINING\")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "print(\"TRAINING COMPLETE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ec16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model \n",
    "print(f\"Saving model to: {output_model_dir}\")\n",
    "trainer.save_model(output_model_dir)\n",
    "tokenizer.save_pretrained(output_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e7faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Evaluation\n",
    "print(\"\\nRunning final evaluation...\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\nFinal Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nModel saved successfully to: {output_model_dir}\")\n",
    "print(\"Training pipeline completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "12venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
